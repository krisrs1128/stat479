---
title: "Boosting and Pocket Measurements"
author: Kris Sankaran
date: 2026-02-11
bibliography: references.bib
format:
  html:
    embed-resources: true
    html-math-method: katex
execute:
    echo: true
    message: false
    warning: false
    cache: false
---

_[Code](https://github.com/krisrs1128/stat479_notes/blob/master/activities/04-pockets.qmd)_

## Motivation

```{r}
#| label: setup
library(tidyverse)
library(DALEX)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(mlr3pipelines)
library(xgboost)
set.seed(20260216)
theme_set(theme_classic())
```

This example revisits the delightful analysis in the article
["Pockets"](https://pudding.cool/2018/08/pockets/) by Jan Diehm and Amber Thomas
for the pudding.  Their question -- are pocket sizes systematically too small in
women's pants?  To this end, they gathered
[data](https://github.com/the-pudding/data/blob/master/pockets/measurements.csv)
on pocket characteristics from major brands. Let's take a quick look.

```{r}
#| label: load-data
pockets <- read_csv("https://github.com/the-pudding/data/raw/refs/heads/master/pockets/measurements.csv")

pockets
```

The main idea of our analysis is to predict whether the pants are mens or womens
pants using all the available features. If we can achieve high accuracy, then
that means the pockets are systematically different, either in their style,
price, or dimensions. Further, we can look at the most important variables to
see which of the pocket size variables are important.

![](figures/pockets.gif)

## Data Processing

Boosting works with either numerical or categorical features. But it will
complain if we pass in character valued columns, so we need to convert those to
factors. Also, `fabric` and `name` are more like ID variables with many levels,
so we'll omit them. We'll also omit `maxHeightFront` because it so strongly
associated with the response that it makes the interpretation steps less
interesting...

```{r}
#| label: preprocess
pockets <- pockets |>
    select(!any_of(c("fabric", "name", "maxHeightFront"))) |>
    mutate(across(where(is.character), as.factor))
```

Here's the processed version of the data.

```{r}
#| label: preview-data
pockets
```

## Hyperparameter Tuning

Next, we define our hyperparameter tuning pipeline. This is quite similar to the
`03-gotv_cart.qmd` analysis from before, where instead of using `classif.rpart`
we're using `classif.xgboost` for boosting. We've also modified the
hyperparameter grid to be relevant to boosting. The most substantial difference
is that we've added a `po("encode")` step, which adds a preprocessing step for
converting categorical features into numerical encodings. While in theory
boosting applies to data of mixed types, the implementation in xgboost only
allows numeircal predictors. We could have done this manually in our
preprocessing above, but `mlr3` gives a helper that manages it during the
modeling pipeline.

```{r}
#| label: tuning-setup
task <- as_task_classif(
    pockets,
    target = "menWomen"
)

learner <- as_learner(
    po("encode") %>>%
    lrn(
        "classif.xgboost",
        nrounds = to_tune(100, 300),
        max_depth = to_tune(1, 3),
        eta = to_tune(1e-3, 1e-1),
        predict_type = "prob"
    )
)

instance <- ti(
  task = task,
  learner = learner,
  resampling = rsmp("cv", folds = 2),
  measures = msr("classif.ce"),
  terminator = trm("none")
)
```

Now that we've setup the pipeline, let's search over hyperparameters to find a
reasonable choice.

```{r}
#| label: optimize
tuner <- tnr("grid_search", resolution = 3, batch_size = 3)
tuner$optimize(instance)
```

Looking at the cross entropy across hyperparameter choices, we can see that the
slowly growing trees (but with some interactions) did the best. The
cross-entropy scale is not as intuitive as overall accuracy, but values near 0
are perfect classification and near $-\log (0.5) \approx 0.69$ are random
guessing, so we're doing quite a lot better than that baseline.

```{r}
#| label: tuning-results
as.data.table(instance$archive) |>
  arrange(classif.ce) |>
  select(1:4)
```

## Refit Model

Let's refit the model on the entire dataset (so far, we've been training on CV
split versions). This is the model that we would use in practice, and it's what
we'll interpret next.

```{r}
#| label: refit
learner$param_set$values <- instance$result_learner_param_vals
learner$train(task) # retrain on all data
fit <- learner$model
```

## Interpretation

One simple check is to compare the predicted probabilities with the actual
class. Since these probabilities barely overlap, we conclude that the available
features are strongly associated to the response. The measured features are
enough to predict men/women pocket type quite reliably.

```{r}
#| label: predicted-probs
#| echo: false
data.frame(y_hat = learner$predict_newdata(pockets)$prob[, 1], y = pockets$menWomen) |>
  ggplot(aes(y_hat, fill = y)) +
  geom_histogram(position = "identity", alpha = 0.7) +
  scale_fill_manual(values = c("#3dafaf", "#b7552c")) +
  labs(x = "Prediction Probability", y = "Count")
```

The xgboost package gives its own variable importance measure. This looks at the
variables which were split most often during training, as well as how much they
increased node purity when they were split. The three

```{r}
#| label: variable-importance
fit <- learner$model$classif.xgboost$model
fit <- attr(fit[[1]], "model") # messy, but seems to be only way to access original model....
xgb.importance(model = fit)
```

Finally we'll make some partial dependence plots. Each line here is a pocket
from the dataset. We've used a special feature -- the `predict_function`
argument --  that let's us study changes in the prediction probabilities rather
than the raw class labels. In the end, each curve shows how the prediction
probability for a pocket changes when we intervene on one of the three plotted
variables. The effect of `minHeightFront` is very clear: as soon as a the
minimum height of the pocket is above a certain value, our model will predict
that it's a mens pants pocket.

```{r}
#| label: partial-dependence
explainer <- DALEX::explain(
  learner,
  data = pockets,
  y = as.numeric(pockets$menWomen),
  predict_function = \(model, newdata) {
    model$predict_newdata(newdata)$prob[, 1]
  }
)

pdp <- model_profile(explainer, variables = c("minHeightFront", "minWidthFront", "rivetHeightFront", "cutout"))
plot(pdp, geom = "profiles")
```

Indeed, if we go back to the raw data, we can see a clear difference in this
variable between mens and women's pants.

```{r}
#| label: height-histogram
#| echo: false
ggplot(pockets) +
    geom_histogram(
        aes(minHeightFront, fill = menWomen),
        position = "identity", alpha = 0.7
    ) +
    scale_fill_manual(values = c("#3dafaf", "#b7552c")) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0))
```