{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c4fdb9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f35046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from importlib import import_module\n",
    "\n",
    "# Import custom helpers\n",
    "helpers = import_module(\"17-helpers\")\n",
    "LlamaForCausalLM = helpers.LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e57490",
   "metadata": {},
   "source": [
    "## Parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and processing configuration\n",
    "MODEL_NAME = 'meta-llama/Llama-3.2-1B'\n",
    "MODEL_SHORT_NAME = 'Llama3.2_1B'\n",
    "PROMPT_TYPE = 'joy_sadness_0'\n",
    "BATCH_SIZE = 1\n",
    "DEVICE_MAP = 'mps'  # 'cpu' for CPU\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('outputs/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f26cfe",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emotion dataset\n",
    "train_data = pd.read_csv('../data/enVent_gen_Data.csv', encoding='ISO-8859-1').iloc[:100, :]\n",
    "train_data['emotion'] = train_data['emotion'].replace('no-emotion', 'neutral')\n",
    "\n",
    "# Define emotions and appraisals\n",
    "emotions_list = [\n",
    "    'anger', 'boredom', 'disgust', 'fear', 'guilt', 'joy', 'neutral',\n",
    "    'pride', 'relief', 'sadness', 'shame', 'surprise', 'trust'\n",
    "]\n",
    "\n",
    "appraisals = [\n",
    "    'predict_event', 'pleasantness', 'other_responsblt', 'chance_control',\n",
    "    'suddenness', 'familiarity', 'unpleasantness', 'goal_relevance',\n",
    "    'self_responsblt', 'predict_conseq', 'goal_support', 'urgency',\n",
    "    'self_control', 'other_control', 'accept_conseq', 'standards',\n",
    "    'social_norms', 'attention', 'not_consider', 'effort'\n",
    "]\n",
    "\n",
    "# Map emotions to IDs\n",
    "emotion_to_id = {emotion: i for i, emotion in enumerate(emotions_list)}\n",
    "train_data['emotion_id'] = train_data['emotion'].map(emotion_to_id).astype(int)\n",
    "\n",
    "# Display sample data\n",
    "train_data[['hidden_emo_text', 'emotion']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c81e1",
   "metadata": {},
   "source": [
    "## Build Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompts with few-shot examples\n",
    "if '_' in PROMPT_TYPE:\n",
    "    shots = PROMPT_TYPE.split('_')[:-1]\n",
    "    prompt_index = int(PROMPT_TYPE.split('_')[-1])\n",
    "else:\n",
    "    shots = []\n",
    "    prompt_index = int(PROMPT_TYPE)\n",
    "\n",
    "prompt_func = helpers.build_prompt(shots=shots, prompt_index=prompt_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbf79c",
   "metadata": {},
   "source": [
    "## Create Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "labels = torch.from_numpy(train_data[['emotion_id'] + appraisals].to_numpy())\n",
    "dataset = helpers.TextDataset(train_data['input_text'].tolist(), labels)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize tokenizer\n",
    "os.makedirs(f'outputs/{MODEL_SHORT_NAME}', exist_ok=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side='left')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load model\n",
    "model = LlamaForCausalLM.from_pretrained(MODEL_NAME, device_map=DEVICE_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec393887",
   "metadata": {},
   "source": [
    "## Extract Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention weights from specific layers\n",
    "dataloader_1bs = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "extraction_layers = list(range(model.config.num_hidden_layers))\n",
    "extraction_locs = [10]  # Location 10 extracts attention weights\n",
    "extraction_tokens = [-1]  # Extract last token\n",
    "\n",
    "# RE-RUN EXTRACTION with fixed code\n",
    "attention_weights, tokenized_inputs = helpers.extract_hidden_states(\n",
    "    dataloader_1bs,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    extraction_locs=extraction_locs,\n",
    "    extraction_layers=extraction_layers,\n",
    "    extraction_tokens=extraction_tokens,\n",
    "    do_final_cat=False,\n",
    "    return_tokenized_input=True\n",
    ")\n",
    "\n",
    "# Save results\n",
    "output_file = f'attention_weights_layers_{extraction_layers}_locs_{extraction_locs}_tokens_{extraction_tokens}.pt'\n",
    "output_path = f'outputs/{MODEL_SHORT_NAME}/{output_file}'\n",
    "torch.save((attention_weights, tokenized_inputs), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f0354d",
   "metadata": {},
   "source": [
    "## Prepare and Save Data for Visualization\n",
    "\n",
    "We'll extract examples and save them as CSV files for easy loading in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "example_indices = range(20)\n",
    "\n",
    "for example_idx in example_indices:\n",
    "    sample_attention = attention_weights[example_idx][0, :, 0, :, 0, :].numpy()  # [layers, heads, tokens]\n",
    "    sample_tokens = tokenized_inputs[example_idx]\n",
    "\n",
    "    n_layers, n_heads, n_tokens = sample_attention.shape\n",
    "\n",
    "    # Create meshgrid for all combinations\n",
    "    layers, heads, tokens = np.meshgrid(\n",
    "        np.arange(n_layers),\n",
    "        np.arange(n_heads),\n",
    "        np.arange(n_tokens),\n",
    "        indexing='ij'\n",
    "    )\n",
    "\n",
    "    # Flatten everything and create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'layer': layers.ravel(),\n",
    "        'head': heads.ravel(),\n",
    "        'token_position': tokens.ravel(),\n",
    "        'token': [sample_tokens[i] for i in tokens.ravel()],\n",
    "        'attention_weight': sample_attention.ravel()\n",
    "    })\n",
    "\n",
    "    output_csv = f'outputs/attention_example_{example_idx}.csv'\n",
    "    df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acbef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
