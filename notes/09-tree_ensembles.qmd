### 9. Tree Ensembles

* motivating case study

* random forest algorithm

* random forest variable importance

* critiques

---

### Learning Outcome

1. Describe the theoretical foundation of intrinsically interpretable models
like sparse regression, gaussian processes, and classification and regression
trees, and apply them to realistic case studies with appropriate validation
checks.
1. Compare the competing definitions of interpretable machine learning, the
motivations behind them, and metrics that can be used to quantify whether they
have been met.

---

### Cell atlases

---

### Tabula muris

---

### Classifying cells

---

### Example marker genes

---

### Exercise: Critiquing claims

---

## Random forest algorithm

---

### High variance $\to$ averaging

---

### Smooth responses $\to$ averaging

---

### Averaging mechanism

---

### Subsampling features

Purpose: Decorrelate the underlying trees

---

### Subsampling observations

---

### Hyperparameters and tuning

subsampling parameters
number of trees to average
can tune using CV

---

## Variable importance

---

### Permutation intuition

---

### Variable importance definition

---

### Computation

---

### Exercise: Variable importance pseudocode

---

### Proximity map

---

### Parwise distances

---

## Critiques

---

### Instability: Efron's Experiment

---

### Realism: Hooker's Experiment

---

### Geometric interpretation